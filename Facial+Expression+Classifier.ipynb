{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fer2013.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              pixels\n",
       "0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the data into labels and features\n",
    "labels, data = data['emotion'], data.drop(['emotion','Usage'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = data[0:34000]\n",
    "labels = labels[0:34000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26cc42fe48>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXvjGNIgXvjEN4oVvTIN44RvTIP8GhAeK/H0M050AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f256e45e198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Taking in the pixels of image i.e the features as a numpy array\n",
    "pixel_data = data.values\n",
    "pixel_data = pixel_data.astype(str)\n",
    "pixel_data = np.core.defchararray.rsplit(pixel_data, sep=None, maxsplit=None)\n",
    "\n",
    "# Visualizing the images using matplotlib\n",
    "first_row = np.asarray((pixel_data)[0][0]).astype('float32')\n",
    "vis_image = first_row.reshape(48,48)\n",
    "plt.imshow(vis_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Reshaping Data\n",
    "\n",
    "This entire part focuses on reshaping the data to be fed into the placeholder tensors which are defined further in the code. This was probably one of the hardest parts of the code and had to be done after reading an extensive amount of numpy documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 2000, 48, 48, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining an empty list to hold values\n",
    "image_data = []\n",
    "# Here we parse through each element in pixel_data, extract and reshape the images and then finally resize it appropriately\n",
    "for i in range(len(pixel_data)):\n",
    "    row_data = np.asarray((pixel_data)[i][0]).astype('float32')\n",
    "    # Normalizing the data to a value between 0 and 1\n",
    "    row_data = row_data/255.0\n",
    "    reshaped_row_data = row_data.reshape(48,48)\n",
    "    image_data.append(reshaped_row_data)\n",
    "big_data = np.vstack(image_data)\n",
    "\n",
    "'''\n",
    "The shape of the array holding image data should be of size (number of batches, number of image samples, height, width, \n",
    "number of input color channels)\n",
    "'''\n",
    "final_data = big_data.reshape(34000,48,48,1)\n",
    "final_data = big_data.reshape(17,2000,48,48,1)\n",
    "final_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 2000, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's set aside the image data and process the labels. Since labels are categorical variables we can one-hot-encode them  \n",
    "encoded_labels = pd.get_dummies(labels)\n",
    "encoded_labels = encoded_labels.as_matrix()\n",
    "encoded_labels = encoded_labels.reshape(17,2000,7)\n",
    "encoded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now to split the data into training and validation split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "'''\n",
    "data_train, labels_train : Data and labels for training model \n",
    "data_test, labels_test : Data and labels for cross_validation \n",
    "'''\n",
    "data_train, data_test, labels_train, labels_test = train_test_split(final_data, encoded_labels, test_size=0.01, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_test = data_test.reshape(2000, 48, 48, 1)\n",
    "labels_test = labels_test.reshape(2000, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    # Returns a tensor for holding input images\n",
    "    return tf.placeholder(tf.float32,shape=[None,image_shape[0],image_shape[1],image_shape[2]], name='x')\n",
    "         \n",
    "def neural_net_label_input(n_classes):\n",
    "    # Returns a tensor for holding image labels  \n",
    "    return tf.placeholder(tf.float32,shape=[None, n_classes], name='y')\n",
    "     \n",
    "def neural_net_keep_prob_input():\n",
    "    # Return a Tensor for keep probability\n",
    "    return tf.placeholder(tf.float32, shape=None, name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    depth = int(x_tensor.get_shape().as_list()[3])\n",
    "    weights = tf.Variable(tf.truncated_normal([conv_ksize[0],conv_ksize[1],depth,conv_num_outputs], stddev=0.05))\n",
    "    bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    \n",
    "    # Convolutional layer + Maxpooling layer\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, weights, strides=[1,conv_strides[0],conv_strides[1], 1], padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, ksize=[1, pool_ksize[0], pool_ksize[1],1], strides=[1, pool_strides[0], pool_strides[1], 1], padding=\"SAME\")\n",
    "    return conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # Storing the dimensions of the tensor as a list into a variable to make it easily accessible.\n",
    "    list_dim = x_tensor.get_shape().as_list()\n",
    "    # Here the reshape function returns a tensor of reduced dimensionality, 2-D in this case with batch size as none.\n",
    "    flattened_tensor = tf.reshape(x_tensor, [-1, list_dim[1]*list_dim[2]*list_dim[3]])\n",
    "    return flattened_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    dimension = x_tensor.get_shape().as_list()[1]\n",
    "    # Here I'm defining separate weights and bias for the fully connected layer..these weights live inside of this function.\n",
    "    weights_full = tf.Variable(tf.truncated_normal([dimension, num_outputs], stddev = 0.05))\n",
    "    bias_full = tf.Variable(tf.zeros([num_outputs]))\n",
    "    # This is a regular hidden layer with weights and biases.\n",
    "    fully_connected = tf.add(tf.matmul(x_tensor, weights_full),bias_full)\n",
    "    fully_connected = tf.nn.relu(fully_connected)\n",
    "    return fully_connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    new_dimension = x_tensor.get_shape().as_list()[1]\n",
    "    # This is very similar to the fully connected layer.\n",
    "    weights_out = tf.Variable(tf.truncated_normal([new_dimension, num_outputs], stddev = 0.05))\n",
    "    bias_out = tf.Variable(tf.zeros([num_outputs]))\n",
    "    #Implementing the output layer.\n",
    "    output_layer = tf.add(tf.matmul(x_tensor, weights_out), bias_out)\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\" \n",
    "    # The first three convolutional + maxpooling layers\n",
    "    neural_net = conv2d_maxpool(x, 32, (5,5), (1,1), (2,2), (1,1))\n",
    "    neural_net = conv2d_maxpool(neural_net, 64, (1,1), (2,2), (4,4), (2,2))\n",
    "    neural_net = conv2d_maxpool(neural_net, 64, (2,2), (1,1), (2,2), (1,1))\n",
    "    neural_net = conv2d_maxpool(neural_net, 128, (2,2), (1,1), (2,2), (1,1))\n",
    "\n",
    "    # Layer to flatten the tensor from the convolutional layers\n",
    "    neural_net = flatten(neural_net)\n",
    "    \n",
    "    # Two fully connected layers with dropout\n",
    "    neural_net = fully_conn(neural_net, 2304)\n",
    "    neural_net = tf.nn.dropout(neural_net, keep_prob)\n",
    "    neural_net = fully_conn(neural_net, 2304)\n",
    "    neural_net = tf.nn.dropout(neural_net, keep_prob)\n",
    "    neural_net = fully_conn(neural_net, 2304)\n",
    "    \n",
    "    # Layer for output\n",
    "    neural_net = output(neural_net, 7)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return neural_net\n",
    "\n",
    "##########Building the Neural Network##########\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((48, 48, 1))\n",
    "y = neural_net_label_input(7)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Two functions to train the network and print stats \n",
    "def train_network(session, optimizer, keep_probability, features,labels):\n",
    "    \n",
    "    # Optimizing the neural net\n",
    "    session.run(optimizer, feed_dict={x:features,y:labels, keep_prob:keep_probability})\n",
    "    pass\n",
    "\n",
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \n",
    "    # Calculating loss and validation accuracy\n",
    "    loss = sess.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: data_test,\n",
    "                y: labels_test,\n",
    "                keep_prob: 1.})\n",
    "    print(\"loss\", loss, \"valid_acc\", valid_acc)\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Defining the hyperparameters\n",
    "epochs = 20\n",
    "batch_size = 200\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on the data\n",
      "Epoch1\n",
      "Batch1\n",
      "loss 1.78498 valid_acc 0.2635\n",
      "Batch2\n",
      "loss 1.81147 valid_acc 0.2635\n",
      "Batch3\n",
      "loss 1.82902 valid_acc 0.2635\n",
      "Batch4\n",
      "loss 1.83739 valid_acc 0.2635\n",
      "Batch5\n",
      "loss 1.80219 valid_acc 0.2635\n",
      "Batch6\n",
      "loss 1.80075 valid_acc 0.2635\n",
      "Batch7\n",
      "loss 1.79418 valid_acc 0.2645\n",
      "Batch8\n",
      "loss 1.78713 valid_acc 0.2635\n",
      "Batch9\n",
      "loss 1.77956 valid_acc 0.264\n",
      "Batch10\n",
      "loss 1.80751 valid_acc 0.2655\n",
      "Batch11\n",
      "loss 1.77635 valid_acc 0.264\n",
      "Batch12\n",
      "loss 1.73083 valid_acc 0.272\n",
      "Batch13\n",
      "loss 1.79359 valid_acc 0.2675\n",
      "Batch14\n",
      "loss 1.77663 valid_acc 0.256\n",
      "Batch15\n",
      "loss 1.76734 valid_acc 0.2735\n",
      "Batch16\n",
      "loss 1.79306 valid_acc 0.276\n",
      "Epoch2\n",
      "Batch1\n",
      "loss 1.73428 valid_acc 0.2595\n",
      "Batch2\n",
      "loss 1.76876 valid_acc 0.285\n",
      "Batch3\n",
      "loss 1.77591 valid_acc 0.2845\n",
      "Batch4\n",
      "loss 1.80711 valid_acc 0.288\n",
      "Batch5\n",
      "loss 1.75773 valid_acc 0.235\n",
      "Batch6\n",
      "loss 1.76741 valid_acc 0.2905\n",
      "Batch7\n",
      "loss 1.73421 valid_acc 0.2975\n",
      "Batch8\n",
      "loss 1.7012 valid_acc 0.3\n",
      "Batch9\n",
      "loss 1.72237 valid_acc 0.2995\n",
      "Batch10\n",
      "loss 1.80162 valid_acc 0.2855\n",
      "Batch11\n",
      "loss 1.70356 valid_acc 0.292\n",
      "Batch12\n",
      "loss 1.63095 valid_acc 0.314\n",
      "Batch13\n",
      "loss 1.67135 valid_acc 0.2915\n",
      "Batch14\n",
      "loss 1.67135 valid_acc 0.311\n",
      "Batch15\n",
      "loss 1.67731 valid_acc 0.2945\n",
      "Batch16\n",
      "loss 1.73102 valid_acc 0.2955\n",
      "Epoch3\n",
      "Batch1\n",
      "loss 1.61291 valid_acc 0.308\n",
      "Batch2\n",
      "loss 1.59228 valid_acc 0.338\n",
      "Batch3\n",
      "loss 1.57278 valid_acc 0.362\n",
      "Batch4\n",
      "loss 1.70296 valid_acc 0.316\n",
      "Batch5\n",
      "loss 1.62573 valid_acc 0.3435\n",
      "Batch6\n",
      "loss 1.64164 valid_acc 0.366\n",
      "Batch7\n",
      "loss 1.5805 valid_acc 0.371\n",
      "Batch8\n",
      "loss 1.5174 valid_acc 0.3735\n",
      "Batch9\n",
      "loss 1.60074 valid_acc 0.377\n",
      "Batch10\n",
      "loss 1.67964 valid_acc 0.3725\n",
      "Batch11\n",
      "loss 1.56717 valid_acc 0.377\n",
      "Batch12\n",
      "loss 1.56482 valid_acc 0.374\n",
      "Batch13\n",
      "loss 1.51945 valid_acc 0.4015\n",
      "Batch14\n",
      "loss 1.55622 valid_acc 0.3855\n",
      "Batch15\n",
      "loss 1.53696 valid_acc 0.3755\n",
      "Batch16\n",
      "loss 1.57582 valid_acc 0.401\n",
      "Epoch4\n",
      "Batch1\n",
      "loss 1.52245 valid_acc 0.398\n",
      "Batch2\n",
      "loss 1.45274 valid_acc 0.398\n",
      "Batch3\n",
      "loss 1.49797 valid_acc 0.3835\n",
      "Batch4\n",
      "loss 1.61023 valid_acc 0.3615\n",
      "Batch5\n",
      "loss 1.46457 valid_acc 0.3965\n",
      "Batch6\n",
      "loss 1.51537 valid_acc 0.3955\n",
      "Batch7\n",
      "loss 1.47851 valid_acc 0.414\n",
      "Batch8\n",
      "loss 1.45427 valid_acc 0.4205\n",
      "Batch9\n",
      "loss 1.50211 valid_acc 0.413\n",
      "Batch10\n",
      "loss 1.63142 valid_acc 0.4205\n",
      "Batch11\n",
      "loss 1.44411 valid_acc 0.415\n",
      "Batch12\n",
      "loss 1.46234 valid_acc 0.4175\n",
      "Batch13\n",
      "loss 1.42606 valid_acc 0.423\n",
      "Batch14\n",
      "loss 1.51647 valid_acc 0.4175\n",
      "Batch15\n",
      "loss 1.4556 valid_acc 0.4215\n",
      "Batch16\n",
      "loss 1.51354 valid_acc 0.3965\n",
      "Epoch5\n",
      "Batch1\n",
      "loss 1.4623 valid_acc 0.4345\n",
      "Batch2\n",
      "loss 1.36138 valid_acc 0.433\n",
      "Batch3\n",
      "loss 1.40199 valid_acc 0.4245\n",
      "Batch4\n",
      "loss 1.54921 valid_acc 0.392\n",
      "Batch5\n",
      "loss 1.41973 valid_acc 0.4235\n",
      "Batch6\n",
      "loss 1.4482 valid_acc 0.4245\n",
      "Batch7\n",
      "loss 1.40345 valid_acc 0.429\n",
      "Batch8\n",
      "loss 1.42269 valid_acc 0.42\n",
      "Batch9\n",
      "loss 1.44376 valid_acc 0.4265\n",
      "Batch10\n",
      "loss 1.55041 valid_acc 0.438\n",
      "Batch11\n",
      "loss 1.36473 valid_acc 0.4405\n",
      "Batch12\n",
      "loss 1.39325 valid_acc 0.4395\n",
      "Batch13\n",
      "loss 1.34373 valid_acc 0.4435\n",
      "Batch14\n",
      "loss 1.44274 valid_acc 0.4335\n",
      "Batch15\n",
      "loss 1.4301 valid_acc 0.416\n",
      "Batch16\n",
      "loss 1.40742 valid_acc 0.436\n",
      "Epoch6\n",
      "Batch1\n",
      "loss 1.43607 valid_acc 0.414\n",
      "Batch2\n",
      "loss 1.37085 valid_acc 0.4315\n",
      "Batch3\n",
      "loss 1.34274 valid_acc 0.433\n",
      "Batch4\n",
      "loss 1.42242 valid_acc 0.441\n",
      "Batch5\n",
      "loss 1.34036 valid_acc 0.432\n",
      "Batch6\n",
      "loss 1.36569 valid_acc 0.4445\n",
      "Batch7\n",
      "loss 1.38363 valid_acc 0.4335\n",
      "Batch8\n",
      "loss 1.35471 valid_acc 0.4395\n",
      "Batch9\n",
      "loss 1.40636 valid_acc 0.4455\n",
      "Batch10\n",
      "loss 1.47647 valid_acc 0.445\n",
      "Batch11\n",
      "loss 1.33807 valid_acc 0.4315\n",
      "Batch12\n",
      "loss 1.33495 valid_acc 0.441\n",
      "Batch13\n",
      "loss 1.34418 valid_acc 0.4595\n",
      "Batch14\n",
      "loss 1.39166 valid_acc 0.441\n",
      "Batch15\n",
      "loss 1.36222 valid_acc 0.4375\n",
      "Batch16\n",
      "loss 1.30111 valid_acc 0.4585\n",
      "Epoch7\n",
      "Batch1\n",
      "loss 1.36493 valid_acc 0.447\n",
      "Batch2\n",
      "loss 1.30026 valid_acc 0.4505\n",
      "Batch3\n",
      "loss 1.29491 valid_acc 0.464\n",
      "Batch4\n",
      "loss 1.34944 valid_acc 0.448\n",
      "Batch5\n",
      "loss 1.2863 valid_acc 0.458\n",
      "Batch6\n",
      "loss 1.30516 valid_acc 0.4675\n",
      "Batch7\n",
      "loss 1.30488 valid_acc 0.462\n",
      "Batch8\n",
      "loss 1.33513 valid_acc 0.461\n",
      "Batch9\n",
      "loss 1.35167 valid_acc 0.456\n",
      "Batch10\n",
      "loss 1.42489 valid_acc 0.4625\n",
      "Batch11\n",
      "loss 1.28115 valid_acc 0.4615\n",
      "Batch12\n",
      "loss 1.27685 valid_acc 0.464\n",
      "Batch13\n",
      "loss 1.27133 valid_acc 0.4605\n",
      "Batch14\n",
      "loss 1.32362 valid_acc 0.4535\n",
      "Batch15\n",
      "loss 1.36668 valid_acc 0.429\n",
      "Batch16\n",
      "loss 1.29029 valid_acc 0.4575\n",
      "Epoch8\n",
      "Batch1\n",
      "loss 1.33304 valid_acc 0.4615\n",
      "Batch2\n",
      "loss 1.24937 valid_acc 0.4615\n",
      "Batch3\n",
      "loss 1.25769 valid_acc 0.465\n",
      "Batch4\n",
      "loss 1.3107 valid_acc 0.474\n",
      "Batch5\n",
      "loss 1.2047 valid_acc 0.47\n",
      "Batch6\n",
      "loss 1.2495 valid_acc 0.472\n",
      "Batch7\n",
      "loss 1.23351 valid_acc 0.4655\n",
      "Batch8\n",
      "loss 1.27977 valid_acc 0.481\n",
      "Batch9\n",
      "loss 1.28716 valid_acc 0.479\n",
      "Batch10\n",
      "loss 1.3615 valid_acc 0.4745\n",
      "Batch11\n",
      "loss 1.24214 valid_acc 0.475\n",
      "Batch12\n",
      "loss 1.23196 valid_acc 0.472\n",
      "Batch13\n",
      "loss 1.2288 valid_acc 0.475\n",
      "Batch14\n",
      "loss 1.26522 valid_acc 0.4665\n",
      "Batch15\n",
      "loss 1.27101 valid_acc 0.4435\n",
      "Batch16\n",
      "loss 1.21632 valid_acc 0.488\n",
      "Epoch9\n",
      "Batch1\n",
      "loss 1.30236 valid_acc 0.47\n",
      "Batch2\n",
      "loss 1.19672 valid_acc 0.4815\n",
      "Batch3\n",
      "loss 1.20736 valid_acc 0.4855\n",
      "Batch4\n",
      "loss 1.22309 valid_acc 0.4785\n",
      "Batch5\n",
      "loss 1.13862 valid_acc 0.4725\n",
      "Batch6\n",
      "loss 1.2135 valid_acc 0.4805\n",
      "Batch7\n",
      "loss 1.14363 valid_acc 0.487\n",
      "Batch8\n",
      "loss 1.25647 valid_acc 0.4875\n",
      "Batch9\n",
      "loss 1.26292 valid_acc 0.497\n",
      "Batch10\n",
      "loss 1.31461 valid_acc 0.4865\n",
      "Batch11\n",
      "loss 1.19782 valid_acc 0.482\n",
      "Batch12\n",
      "loss 1.19044 valid_acc 0.4805\n",
      "Batch13\n",
      "loss 1.20181 valid_acc 0.482\n",
      "Batch14\n",
      "loss 1.21827 valid_acc 0.4795\n",
      "Batch15\n",
      "loss 1.23198 valid_acc 0.485\n",
      "Batch16\n",
      "loss 1.18093 valid_acc 0.4965\n",
      "Epoch10\n",
      "Batch1\n",
      "loss 1.22823 valid_acc 0.5025\n",
      "Batch2\n",
      "loss 1.16798 valid_acc 0.5\n",
      "Batch3\n",
      "loss 1.15943 valid_acc 0.49\n",
      "Batch4\n",
      "loss 1.18235 valid_acc 0.4895\n",
      "Batch5\n",
      "loss 1.12893 valid_acc 0.477\n",
      "Batch6\n",
      "loss 1.17109 valid_acc 0.504\n",
      "Batch7\n",
      "loss 1.14256 valid_acc 0.497\n",
      "Batch8\n",
      "loss 1.16894 valid_acc 0.499\n",
      "Batch9\n",
      "loss 1.24308 valid_acc 0.482\n",
      "Batch10\n",
      "loss 1.25446 valid_acc 0.4765\n",
      "Batch11\n",
      "loss 1.1589 valid_acc 0.4995\n",
      "Batch12\n",
      "loss 1.16161 valid_acc 0.4905\n",
      "Batch13\n",
      "loss 1.18718 valid_acc 0.5045\n",
      "Batch14\n",
      "loss 1.18216 valid_acc 0.4945\n",
      "Batch15\n",
      "loss 1.16828 valid_acc 0.485\n",
      "Batch16\n",
      "loss 1.14376 valid_acc 0.4985\n",
      "Epoch11\n",
      "Batch1\n",
      "loss 1.17203 valid_acc 0.506\n",
      "Batch2\n",
      "loss 1.12935 valid_acc 0.5055\n",
      "Batch3\n",
      "loss 1.10667 valid_acc 0.5115\n",
      "Batch4\n",
      "loss 1.11191 valid_acc 0.4985\n",
      "Batch5\n",
      "loss 1.08617 valid_acc 0.495\n",
      "Batch6\n",
      "loss 1.11957 valid_acc 0.5035\n",
      "Batch7\n",
      "loss 1.09811 valid_acc 0.5005\n",
      "Batch8\n",
      "loss 1.13713 valid_acc 0.5025\n",
      "Batch9\n",
      "loss 1.19321 valid_acc 0.4925\n",
      "Batch10\n",
      "loss 1.22474 valid_acc 0.475\n",
      "Batch11\n",
      "loss 1.095 valid_acc 0.481\n",
      "Batch12\n",
      "loss 1.12613 valid_acc 0.495\n",
      "Batch13\n",
      "loss 1.11352 valid_acc 0.5055\n",
      "Batch14\n",
      "loss 1.11705 valid_acc 0.4845\n",
      "Batch15\n",
      "loss 1.17801 valid_acc 0.481\n",
      "Batch16\n",
      "loss 1.08647 valid_acc 0.4965\n",
      "Epoch12\n",
      "Batch1\n",
      "loss 1.15943 valid_acc 0.5065\n",
      "Batch2\n",
      "loss 1.06967 valid_acc 0.506\n",
      "Batch3\n",
      "loss 1.04114 valid_acc 0.505\n",
      "Batch4\n",
      "loss 1.05505 valid_acc 0.4995\n",
      "Batch5\n",
      "loss 1.02752 valid_acc 0.5075\n",
      "Batch6\n",
      "loss 1.1094 valid_acc 0.4975\n",
      "Batch7\n",
      "loss 1.05858 valid_acc 0.494\n",
      "Batch8\n",
      "loss 1.13647 valid_acc 0.511\n",
      "Batch9\n",
      "loss 1.12899 valid_acc 0.4995\n",
      "Batch10\n",
      "loss 1.15893 valid_acc 0.5075\n",
      "Batch11\n",
      "loss 1.03105 valid_acc 0.498\n",
      "Batch12\n",
      "loss 1.1467 valid_acc 0.4885\n",
      "Batch13\n",
      "loss 1.10522 valid_acc 0.5115\n",
      "Batch14\n",
      "loss 1.07602 valid_acc 0.5125\n",
      "Batch15\n",
      "loss 1.09051 valid_acc 0.4995\n",
      "Batch16\n",
      "loss 1.05828 valid_acc 0.494\n",
      "Epoch13\n",
      "Batch1\n",
      "loss 1.1594 valid_acc 0.517\n",
      "Batch2\n",
      "loss 1.05354 valid_acc 0.5145\n",
      "Batch3\n",
      "loss 1.00431 valid_acc 0.4975\n",
      "Batch4\n",
      "loss 0.988986 valid_acc 0.5045\n",
      "Batch5\n",
      "loss 0.966044 valid_acc 0.5045\n",
      "Batch6\n",
      "loss 1.02621 valid_acc 0.5055\n",
      "Batch7\n",
      "loss 1.05106 valid_acc 0.4985\n",
      "Batch8\n",
      "loss 1.09486 valid_acc 0.496\n",
      "Batch9\n",
      "loss 1.11724 valid_acc 0.5095\n",
      "Batch10\n",
      "loss 1.09816 valid_acc 0.5045\n",
      "Batch11\n",
      "loss 0.989613 valid_acc 0.4965\n",
      "Batch12\n",
      "loss 1.08602 valid_acc 0.501\n",
      "Batch13\n",
      "loss 1.07727 valid_acc 0.507\n",
      "Batch14\n",
      "loss 1.08293 valid_acc 0.4955\n",
      "Batch15\n",
      "loss 1.06828 valid_acc 0.5125\n",
      "Batch16\n",
      "loss 1.00027 valid_acc 0.516\n",
      "Epoch14\n",
      "Batch1\n",
      "loss 1.09031 valid_acc 0.5225\n",
      "Batch2\n",
      "loss 1.0326 valid_acc 0.5085\n",
      "Batch3\n",
      "loss 0.936428 valid_acc 0.51\n",
      "Batch4\n",
      "loss 0.905067 valid_acc 0.51\n",
      "Batch5\n",
      "loss 0.932394 valid_acc 0.505\n",
      "Batch6\n",
      "loss 0.98592 valid_acc 0.512\n",
      "Batch7\n",
      "loss 1.00848 valid_acc 0.5115\n",
      "Batch8\n",
      "loss 1.0648 valid_acc 0.5005\n",
      "Batch9\n",
      "loss 1.09194 valid_acc 0.5025\n",
      "Batch10\n",
      "loss 1.11636 valid_acc 0.488\n",
      "Batch11\n",
      "loss 1.0051 valid_acc 0.505\n",
      "Batch12\n",
      "loss 1.05079 valid_acc 0.493\n",
      "Batch13\n",
      "loss 1.06038 valid_acc 0.5225\n",
      "Batch14\n",
      "loss 0.997085 valid_acc 0.511\n",
      "Batch15\n",
      "loss 1.01405 valid_acc 0.518\n",
      "Batch16\n",
      "loss 0.976239 valid_acc 0.5185\n",
      "Epoch15\n",
      "Batch1\n",
      "loss 1.05091 valid_acc 0.5195\n",
      "Batch2\n",
      "loss 0.961532 valid_acc 0.5155\n",
      "Batch3\n",
      "loss 0.85028 valid_acc 0.5115\n",
      "Batch4\n",
      "loss 0.846183 valid_acc 0.517\n",
      "Batch5\n",
      "loss 0.838934 valid_acc 0.5115\n",
      "Batch6\n",
      "loss 0.940898 valid_acc 0.506\n",
      "Batch7\n",
      "loss 0.952779 valid_acc 0.517\n",
      "Batch8\n",
      "loss 1.00881 valid_acc 0.522\n",
      "Batch9\n",
      "loss 1.02087 valid_acc 0.52\n",
      "Batch10\n",
      "loss 1.0472 valid_acc 0.5175\n",
      "Batch11\n",
      "loss 0.889088 valid_acc 0.5115\n",
      "Batch12\n",
      "loss 0.997925 valid_acc 0.5065\n",
      "Batch13\n",
      "loss 1.00743 valid_acc 0.528\n",
      "Batch14\n",
      "loss 0.937527 valid_acc 0.533\n",
      "Batch15\n",
      "loss 1.04134 valid_acc 0.505\n",
      "Batch16\n",
      "loss 0.954813 valid_acc 0.532\n",
      "Epoch16\n",
      "Batch1\n",
      "loss 1.04094 valid_acc 0.516\n",
      "Batch2\n",
      "loss 0.963335 valid_acc 0.518\n",
      "Batch3\n",
      "loss 0.845628 valid_acc 0.5165\n",
      "Batch4\n",
      "loss 0.836216 valid_acc 0.5205\n",
      "Batch5\n",
      "loss 0.818377 valid_acc 0.5075\n",
      "Batch6\n",
      "loss 0.96367 valid_acc 0.499\n",
      "Batch7\n",
      "loss 0.900061 valid_acc 0.5185\n",
      "Batch8\n",
      "loss 0.958759 valid_acc 0.5165\n",
      "Batch9\n",
      "loss 0.952653 valid_acc 0.5215\n",
      "Batch10\n",
      "loss 0.969581 valid_acc 0.532\n",
      "Batch11\n",
      "loss 0.805517 valid_acc 0.515\n",
      "Batch12\n",
      "loss 0.946853 valid_acc 0.508\n",
      "Batch13\n",
      "loss 0.983396 valid_acc 0.52\n",
      "Batch14\n",
      "loss 0.924436 valid_acc 0.5235\n",
      "Batch15\n",
      "loss 0.950636 valid_acc 0.528\n",
      "Batch16\n",
      "loss 0.897111 valid_acc 0.525\n",
      "Epoch17\n",
      "Batch1\n",
      "loss 0.93681 valid_acc 0.532\n",
      "Batch2\n",
      "loss 0.868577 valid_acc 0.5255\n",
      "Batch3\n",
      "loss 0.844128 valid_acc 0.5285\n",
      "Batch4\n",
      "loss 0.797782 valid_acc 0.522\n",
      "Batch5\n",
      "loss 0.787175 valid_acc 0.505\n",
      "Batch6\n",
      "loss 0.879247 valid_acc 0.506\n",
      "Batch7\n",
      "loss 0.857393 valid_acc 0.5215\n",
      "Batch8\n",
      "loss 0.925449 valid_acc 0.513\n",
      "Batch9\n",
      "loss 1.00005 valid_acc 0.505\n",
      "Batch10\n",
      "loss 0.981332 valid_acc 0.5285\n",
      "Batch11\n",
      "loss 0.834459 valid_acc 0.5055\n",
      "Batch12\n",
      "loss 0.926097 valid_acc 0.521\n",
      "Batch13\n",
      "loss 0.97442 valid_acc 0.5185\n",
      "Batch14\n",
      "loss 0.969615 valid_acc 0.5095\n",
      "Batch15\n",
      "loss 0.981317 valid_acc 0.505\n",
      "Batch16\n",
      "loss 0.853562 valid_acc 0.5285\n",
      "Epoch18\n",
      "Batch1\n",
      "loss 0.978687 valid_acc 0.5015\n",
      "Batch2\n",
      "loss 0.812494 valid_acc 0.523\n",
      "Batch3\n",
      "loss 0.794186 valid_acc 0.521\n",
      "Batch4\n",
      "loss 0.782554 valid_acc 0.525\n",
      "Batch5\n",
      "loss 0.69607 valid_acc 0.525\n",
      "Batch6\n",
      "loss 0.842258 valid_acc 0.5085\n",
      "Batch7\n",
      "loss 0.790015 valid_acc 0.5275\n",
      "Batch8\n",
      "loss 0.875977 valid_acc 0.5145\n",
      "Batch9\n",
      "loss 1.02387 valid_acc 0.486\n",
      "Batch10\n",
      "loss 0.92431 valid_acc 0.5215\n",
      "Batch11\n",
      "loss 0.816956 valid_acc 0.5025\n",
      "Batch12\n",
      "loss 0.910548 valid_acc 0.52\n",
      "Batch13\n",
      "loss 0.982727 valid_acc 0.5235\n",
      "Batch14\n",
      "loss 0.906543 valid_acc 0.527\n",
      "Batch15\n",
      "loss 0.89982 valid_acc 0.5225\n",
      "Batch16\n",
      "loss 0.796487 valid_acc 0.5295\n",
      "Epoch19\n",
      "Batch1\n",
      "loss 0.893863 valid_acc 0.5305\n",
      "Batch2\n",
      "loss 0.766362 valid_acc 0.517\n",
      "Batch3\n",
      "loss 0.757055 valid_acc 0.5245\n",
      "Batch4\n",
      "loss 0.7322 valid_acc 0.5165\n",
      "Batch5\n",
      "loss 0.731673 valid_acc 0.512\n",
      "Batch6\n",
      "loss 0.792783 valid_acc 0.5065\n",
      "Batch7\n",
      "loss 0.752677 valid_acc 0.523\n",
      "Batch8\n",
      "loss 0.873376 valid_acc 0.5185\n",
      "Batch9\n",
      "loss 0.917457 valid_acc 0.51\n",
      "Batch10\n",
      "loss 0.850586 valid_acc 0.5245\n",
      "Batch11\n",
      "loss 0.767043 valid_acc 0.511\n",
      "Batch12\n",
      "loss 0.858023 valid_acc 0.52\n",
      "Batch13\n",
      "loss 0.916247 valid_acc 0.5265\n",
      "Batch14\n",
      "loss 0.857762 valid_acc 0.5325\n",
      "Batch15\n",
      "loss 0.804339 valid_acc 0.518\n",
      "Batch16\n",
      "loss 0.782879 valid_acc 0.522\n",
      "Epoch20\n",
      "Batch1\n",
      "loss 0.865241 valid_acc 0.532\n",
      "Batch2\n",
      "loss 0.726542 valid_acc 0.5275\n",
      "Batch3\n",
      "loss 0.729898 valid_acc 0.527\n",
      "Batch4\n",
      "loss 0.685518 valid_acc 0.514\n",
      "Batch5\n",
      "loss 0.631198 valid_acc 0.5275\n",
      "Batch6\n",
      "loss 0.741243 valid_acc 0.508\n",
      "Batch7\n",
      "loss 0.745388 valid_acc 0.527\n",
      "Batch8\n",
      "loss 0.798469 valid_acc 0.514\n",
      "Batch9\n",
      "loss 0.796644 valid_acc 0.5225\n",
      "Batch10\n",
      "loss 0.821799 valid_acc 0.534\n",
      "Batch11\n",
      "loss 0.672922 valid_acc 0.5195\n",
      "Batch12\n",
      "loss 0.804129 valid_acc 0.5405\n",
      "Batch13\n",
      "loss 0.881632 valid_acc 0.525\n",
      "Batch14\n",
      "loss 0.804087 valid_acc 0.534\n",
      "Batch15\n",
      "loss 0.756985 valid_acc 0.5205\n",
      "Batch16\n",
      "loss 0.801916 valid_acc 0.5095\n"
     ]
    }
   ],
   "source": [
    "# Finally let's get training \n",
    "print(\"Training on the data\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch\"+ str(epoch+1))\n",
    "        num_batches = 16\n",
    "        for batch in range(num_batches):\n",
    "            print(\"Batch\"+ str(batch+1))\n",
    "            for offset in range(0, 2000, batch_size):\n",
    "                batch_x, batch_y = data_train[batch][offset:offset+batch_size], labels_train[batch][offset:offset+batch_size]\n",
    "                train_network(sess, optimizer, keep_probability, batch_x, batch_y )\n",
    "            print_stats(sess, batch_x, batch_y, cost, accuracy)     "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
