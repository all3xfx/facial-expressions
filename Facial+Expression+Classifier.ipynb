{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fer2013.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the data into labels and features\n",
    "labels, data = data['emotion'], data.drop(['emotion','Usage'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking in the pixels of image i.e the features as a numpy array\n",
    "pixel_data = data.values\n",
    "pixel_data = pixel_data.astype(str)\n",
    "# Here we know that the images are one-dimensional(grayscale) since the depth of the matrix 1 of every element\n",
    "pixel_data = np.core.defchararray.rsplit(pixel_data, sep=None, maxsplit=None)\n",
    "pixel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now let's set aside the image data and process the labels. Since labels are categorical variables we can one-hot-encode them\n",
    "encoded_labels = pd.get_dummies(labels)\n",
    "encoded_labels = encoded_labels.as_matrix()\n",
    "encoded_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Defining tensors for inputs and labels \n",
    "\n",
    "# Placeholder tensor for inputs. In this case, input is a 28x28 image.\n",
    "input_image_data = tf.placeholder(tf.float32,shape=[None,28,28,1])\n",
    "\n",
    "# Placeholder for labels \n",
    "label_data = tf.placeholder(tf.float32, shape=[None,7])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32,shape=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now let's start off by building the network\n",
    "def build_cnn(inputs, labels):\n",
    "    \n",
    "    # Input layer of conv-net\n",
    "    input_layer = input_image_data\n",
    "    \n",
    "    # First convolutional layer\n",
    "    neural_net = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    # First pooling layer\n",
    "    neural_net =  tf.layers.max_pooling2d(inputs=neural_net, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # Second convolutional layer \n",
    "    neural_net = tf.layers.conv2d(\n",
    "      inputs=neural_net,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    # Second pooling layer\n",
    "    neural_net = tf.layers.max_pooling2d(inputs=neural_net, pool_size=[2,2], strides=2)\n",
    "    \n",
    "    # Flattening layer\n",
    "    neural_net = tf.reshape(neural_net, [-1, 7 * 7 * 64])\n",
    "    \n",
    "    # Two stacked Fully connected layers\n",
    "    neural_net = tf.layers.dense(inputs=neural_net, units=1024, activation=tf.nn.relu)\n",
    "    neural_net = tf.layers.dropout(inputs=neural_net, rate=0.4)\n",
    "    \n",
    "    neural_net = tf.layers.dense(inputs=neural_net, units=1024, activation=tf.nn.relu)\n",
    "    neural_net = tf.layers.dropout(inputs=neural_net, rate=0.4)\n",
    "    \n",
    "    # Output Layer\n",
    "    logits = tf.layers.dense(inputs=neural_net, units=7)\n",
    "    \n",
    "    return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calling the build_cnn function \n",
    "cnn_built = build_cnn(input_image_data, label_data)\n",
    "cnn_built = tf.identity(cnn_built, name='cnn')\n",
    "\n",
    "# Loss and optimizer \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=cnn_built, labels=labels))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Two functions to train the network and print stats \n",
    "def train_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \n",
    "    # Optimizing the neural net\n",
    "    session.run(optimizer, feed_dict={x:feature_batch,y:label_batch, keep_prob:keep_probability})\n",
    "    pass\n",
    "\n",
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \n",
    "    # Calculating loss and validation accuracy\n",
    "    loss = sess.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.})\n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: valid_features,\n",
    "                y: valid_labels,\n",
    "                keep_prob: 1.})\n",
    "    print(\"loss\", loss, \"valid_acc\", valid_acc)\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Defining the hyperparameters\n",
    "epochs = 30\n",
    "batch_size = 128\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Finally let's get training \n",
    "print(\"Training on the data\")\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_network(session,optimizer, keep_probability, feature_batch, label_batch)\n",
    "    \n",
    "    print('Epoch {:>2}:  '.format(epoch + 1), end='')\n",
    "    print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
